import os

from dotenv import load_dotenv
from openai import OpenAI
from pydantic import BaseModel, Field
from typing import List
import time

# Pydantic model for a descriptive question
class DescriptiveQuestion(BaseModel):
    question: str
    correct_answer: str
    marks: int


# Pydantic model for the descriptive quiz request
class DescriptiveQuizRequest(BaseModel):
    topic: str
    total_marks: int
    num_questions: int

# Pydantic model for the descriptive quiz response generated by AI
class DescriptiveQuizResponse(BaseModel):
    title: str
    total_marks: int
    questions: List[str]


# Setting up the client for OpenAI requests

load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=API_KEY)

SYSTEM_ROLE = "You are a teacher of Bachelor Level Digital Logic Design"


def generate_descriptive_quiz(request: DescriptiveQuizRequest) -> DescriptiveQuizResponse:
    """Generate a descriptive-answer quiz using structured OpenAI response with Pydantic."""

    prompt = f"""
    Create a descriptive-answer quiz on the topic: {request.topic}.
    Total marks: {request.total_marks}.
    Number of questions: {request.num_questions}.
    """
    start = time.perf_counter() # determining the starting time of the request

    response = client.responses.parse(
        model="gpt-4o-mini",
        input=[
            {"role": "system", "content": SYSTEM_ROLE},
            {"role": "user", "content": prompt},
        ],
        text_format=DescriptiveQuizResponse,
    )

    end = time.perf_counter()  # determining the ending time of the request
    latency = (end - start) # calculating the time taken for the request

    print(f"model: {response.model}")
    # Calculating the costs and printing the stats
    usage = response.usage

    print(f"Input tokens: {usage.input_tokens} and Input cost: {(usage.input_tokens * 0.00015 / 1000):.6f}")
    print(f"Output tokens: {usage.output_tokens} and Output cost: {(usage.output_tokens * 0.0006 / 1000):.6f}")
    print(
        f"Total tokens: {usage.total_tokens} and total cost {((usage.input_tokens * 0.00015 / 1000) + (usage.output_tokens * 0.0006 / 1000)):.6f}")
    print(f"Latency(time taken in seconds): {round(latency, 2)}")

    return response.output_parsed


# Calling here right now to avoid being called in the inherited files
if __name__ == "__main__":

    req = DescriptiveQuizRequest(
        topic="logic gates",
        total_marks=20,
        num_questions=4
    )

    quiz = generate_descriptive_quiz(req)
    json_quiz = quiz.model_dump_json(indent=2) # a pretty json string which has 2 indents spacing between each level
    print(json_quiz)